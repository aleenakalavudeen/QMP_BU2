{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Format:\n",
    "\n",
    "Have a main folder with the data split as train, val, and test and inside it should have a images and labels folder with the filenames same.  \n",
    "For Detection:  \n",
    "\n",
    "\n",
    "Data  \n",
    " -- train  \n",
    " ----images  \n",
    " ------1.jpg  \n",
    " ------2.jpg  \n",
    " ----labels  \n",
    " ------1.txt  \n",
    " ------2.txt  \n",
    " -- val  \n",
    " ----images  \n",
    " ------1.jpg  \n",
    " ------2.jpg  \n",
    " ----labels  \n",
    " ------1.txt  \n",
    " ------2.txt  \n",
    " -- test  \n",
    " ----images  \n",
    " ------1.jpg  \n",
    " ------2.jpg  \n",
    " ----labels  \n",
    " ------1.txt  \n",
    " ------2.txt  \n",
    "\n",
    " For Classification: \n",
    " for the data the format would be  \n",
    "Data_Classify  \n",
    "--  images  \n",
    "---- class1  \n",
    "------ 1.jpg  \n",
    "------ 2.jpg  \n",
    "  ---- class2  \n",
    "------ 1.jpg  \n",
    "------ 2.jpg \n",
    "\n",
    "## Label Format\n",
    "Each txt file should correspond to the image and the format for each bounding box should be as below \n",
    "\n",
    "> class_id x_center y_center box_width box_height (normalised to image's weight and height)\n",
    "\n",
    "One row per object bounding box.  \n",
    "Each row must contain: class_index x_center y_center width height.  \n",
    "Coordinates must be normalized to a range between 0 and 1. To achieve this, divide the pixel values of x_center and width by the image's total width, and divide y_center and height by the image's total height.  \n",
    "Class indices are zero-indexed (i.e., the first class is represented by 0, the second by 1, and so forth).\n",
    "\n",
    "# YAML file\n",
    "Make a yaml file of the following format, this yaml file should be referenced to when training or testing\n",
    "  \n",
    "  train: ./path_to_train_images_folder/images  \n",
    "  val: ./path_to_val_images_folder/images  \n",
    "  test: ./path_to_test_images_folder/images  \n",
    "  nc: number of classes  \n",
    "  names: ['a', 'b', 'c', 'd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5 \n",
    "!cd yolov5\n",
    "!pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "Run in the terminal  \n",
    "\"./yolov5/train.py\" from the git clone  \n",
    "\"./data.yaml\" the yaml file u made above  \n",
    "\"yolov5s.pt\" from the git clone, later can even use ur own weights to train more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection, set batch size to -1 for it to auto select an optimized version\n",
    "!python ./yolov5-master/train.py --data ./data.yaml --weights yolov5s.pt --img 640 --epochs 50 --batch-size 16\n",
    "\n",
    "# Recognition\n",
    "!python ./yolov5-master/classify/train.py --data ./data.yaml --weights yolov5s-cls.pt --img 640 --epochs 50 --batch-size 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection and Recognition\n",
    "# add path for trained weights, you will find them in the runs/train/exp/weights folder\n",
    "!python val.py --task \"test\" --weights ./path_to_weights --data data.yaml --img 640 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Weights\n",
    "\n",
    "you will find the trained weights in the folder run under the weights folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_model = torch.hub.load('../yolov5-master/', 'custom', path='../yolov5-master/runs/train/exp4/weights/best.pt', force_reload=True, source='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "img = cv2.imread(path)\n",
    "cv2.imshow(\"display\", img)\n",
    "results = detect_model(img)\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights, here can change to yolov8n-cls\n",
    "model = YOLO(\"yolov8n.pt\") \n",
    "\n",
    "# train, data - add the yaml u made, same as yolov5\n",
    "results = model.train(data=\"data.yaml\", epochs=100, imgsz=640)\n",
    "\n",
    "# reload\n",
    "recog_model = YOLO('path_to_weights') \n",
    "\n",
    "# test\n",
    "model.test()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
